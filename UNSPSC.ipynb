{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Reading data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('UNSPSCdataset.csv',encoding='mac_roman',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaterialDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRTEL BILLS 22aug TO 23 AUG    2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRTEL MOBILE BILLS 23nov O 22 dec 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aluminum fabrication work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aluminum fabrication work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>civil &amp; plumbing work @ BMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MaterialDescription\n",
       "0    AIRTEL BILLS 22aug TO 23 AUG    2012\n",
       "1   AIRTEL MOBILE BILLS 23nov O 22 dec 12\n",
       "2               aluminum fabrication work\n",
       "3               aluminum fabrication work\n",
       "4             civil & plumbing work @ BMT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = 'UNSPSC_Final'\n",
    "y = df[output]\n",
    "features = ['MaterialDescription']\n",
    "X = df[features]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Downloading stopwords from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> stopwords\n",
      "    Downloading package stopwords to /home/carnd/nltk_data...\n",
      "      Unzipping corpora/stopwords.zip.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()  # Download text data sets, including stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "\n",
    "def description_to_words(review_text):\n",
    "    \n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aluminum fabrication work\n"
     ]
    }
   ],
   "source": [
    "clean_review = description_to_words(df['MaterialDescription'][3] )\n",
    "print(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set UNSPSC description...\n",
      "\n",
      "Description 1000 of 45001\n",
      "\n",
      "Description 2000 of 45001\n",
      "\n",
      "Description 3000 of 45001\n",
      "\n",
      "Description 4000 of 45001\n",
      "\n",
      "Description 5000 of 45001\n",
      "\n",
      "Description 6000 of 45001\n",
      "\n",
      "Description 7000 of 45001\n",
      "\n",
      "Description 8000 of 45001\n",
      "\n",
      "Description 9000 of 45001\n",
      "\n",
      "Description 10000 of 45001\n",
      "\n",
      "Description 11000 of 45001\n",
      "\n",
      "Description 12000 of 45001\n",
      "\n",
      "Description 13000 of 45001\n",
      "\n",
      "Description 14000 of 45001\n",
      "\n",
      "Description 15000 of 45001\n",
      "\n",
      "Description 16000 of 45001\n",
      "\n",
      "Description 17000 of 45001\n",
      "\n",
      "Description 18000 of 45001\n",
      "\n",
      "Description 19000 of 45001\n",
      "\n",
      "Description 20000 of 45001\n",
      "\n",
      "Description 21000 of 45001\n",
      "\n",
      "Description 22000 of 45001\n",
      "\n",
      "Description 23000 of 45001\n",
      "\n",
      "Description 24000 of 45001\n",
      "\n",
      "Description 25000 of 45001\n",
      "\n",
      "Description 26000 of 45001\n",
      "\n",
      "Description 27000 of 45001\n",
      "\n",
      "Description 28000 of 45001\n",
      "\n",
      "Description 29000 of 45001\n",
      "\n",
      "Description 30000 of 45001\n",
      "\n",
      "Description 31000 of 45001\n",
      "\n",
      "Description 32000 of 45001\n",
      "\n",
      "Description 33000 of 45001\n",
      "\n",
      "Description 34000 of 45001\n",
      "\n",
      "Description 35000 of 45001\n",
      "\n",
      "Description 36000 of 45001\n",
      "\n",
      "Description 37000 of 45001\n",
      "\n",
      "Description 38000 of 45001\n",
      "\n",
      "Description 39000 of 45001\n",
      "\n",
      "Description 40000 of 45001\n",
      "\n",
      "Description 41000 of 45001\n",
      "\n",
      "Description 42000 of 45001\n",
      "\n",
      "Description 43000 of 45001\n",
      "\n",
      "Description 44000 of 45001\n",
      "\n",
      "Description 45000 of 45001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "num_description = df['MaterialDescription'].size\n",
    "print(\"Cleaning and parsing the training set UNSPSC description...\\n\")\n",
    "clean_description = []\n",
    "for i in range(0, num_description):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(\"Description %d of %d\\n\" % ( i+1, num_description))                                                                  \n",
    "    clean_description.append( description_to_words(df['MaterialDescription'][i] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Printing the list containing the useful words extracted from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airtel bills aug aug', 'airtel mobile bills nov dec', 'aluminum fabrication work', 'aluminum fabrication work', 'civil plumbing work bmt', 'electrical wk elr lab mhb', 'glass door fr gastro main door', 'hosp tack fixing st flr medicine', 'magazine week magic pot', 'magazine week magic pot']\n"
     ]
    }
   ],
   "source": [
    "print(clean_description[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Creating bag of words from the useful word extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "(45001, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the bag of words...\\n\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 8000) \n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_description)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Random Forest for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Total time taken to train the model is  1851.8335661888123\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Training the random forest...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 500) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "start = time.time()\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( train_data_features, df['UNSPSC_Final'] )\n",
    "end = time.time() \n",
    "\n",
    "total = end - start\n",
    "\n",
    "print(\"Total time taken to train the model is \", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49657, 20)\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "desc 1000 of 49657\n",
      "\n",
      "desc 2000 of 49657\n",
      "\n",
      "desc 3000 of 49657\n",
      "\n",
      "desc 4000 of 49657\n",
      "\n",
      "desc 5000 of 49657\n",
      "\n",
      "desc 6000 of 49657\n",
      "\n",
      "desc 7000 of 49657\n",
      "\n",
      "desc 8000 of 49657\n",
      "\n",
      "desc 9000 of 49657\n",
      "\n",
      "desc 10000 of 49657\n",
      "\n",
      "desc 11000 of 49657\n",
      "\n",
      "desc 12000 of 49657\n",
      "\n",
      "desc 13000 of 49657\n",
      "\n",
      "desc 14000 of 49657\n",
      "\n",
      "desc 15000 of 49657\n",
      "\n",
      "desc 16000 of 49657\n",
      "\n",
      "desc 17000 of 49657\n",
      "\n",
      "desc 18000 of 49657\n",
      "\n",
      "desc 19000 of 49657\n",
      "\n",
      "desc 20000 of 49657\n",
      "\n",
      "desc 21000 of 49657\n",
      "\n",
      "desc 22000 of 49657\n",
      "\n",
      "desc 23000 of 49657\n",
      "\n",
      "desc 24000 of 49657\n",
      "\n",
      "desc 25000 of 49657\n",
      "\n",
      "desc 26000 of 49657\n",
      "\n",
      "desc 27000 of 49657\n",
      "\n",
      "desc 28000 of 49657\n",
      "\n",
      "desc 29000 of 49657\n",
      "\n",
      "desc 30000 of 49657\n",
      "\n",
      "desc 31000 of 49657\n",
      "\n",
      "desc 32000 of 49657\n",
      "\n",
      "desc 33000 of 49657\n",
      "\n",
      "desc 34000 of 49657\n",
      "\n",
      "desc 35000 of 49657\n",
      "\n",
      "desc 36000 of 49657\n",
      "\n",
      "desc 37000 of 49657\n",
      "\n",
      "desc 38000 of 49657\n",
      "\n",
      "desc 39000 of 49657\n",
      "\n",
      "desc 40000 of 49657\n",
      "\n",
      "desc 41000 of 49657\n",
      "\n",
      "desc 42000 of 49657\n",
      "\n",
      "desc 43000 of 49657\n",
      "\n",
      "desc 44000 of 49657\n",
      "\n",
      "desc 45000 of 49657\n",
      "\n",
      "desc 46000 of 49657\n",
      "\n",
      "desc 47000 of 49657\n",
      "\n",
      "desc 48000 of 49657\n",
      "\n",
      "desc 49000 of 49657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = pd.read_csv('UNSPSCtestDataSet.csv',encoding='mac_roman',low_memory=False)\n",
    "# Verify that there are 25,000 rows and 2 columns\n",
    "print(test.shape)\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_desc = len(test[\"MaterialDescription\"])\n",
    "clean_test_desc = [] \n",
    "\n",
    "print(\"Cleaning and parsing the test set movie reviews...\\n\")\n",
    "for i in range(0,num_desc):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print(\"desc %d of %d\\n\" % (i+1, num_desc))\n",
    "    clean_desc = description_to_words(test[\"MaterialDescription\"][i])\n",
    "    clean_test_desc.append(clean_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_desc)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"sentiment\" column\n",
    "output = pd.DataFrame( data={\"unspscRFcode\":result} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"finalunspscRF8000-500.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57307126890468618"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "fromcsv = pd.read_csv(\"finalunspscRF8000-500.csv\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test['UNSPSC_Final'],fromcsv['unspscRFcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
