{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('UNSPSCdataset.csv',encoding='mac_roman',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaterialDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRTEL BILLS 22aug TO 23 AUG    2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRTEL MOBILE BILLS 23nov O 22 dec 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aluminum fabrication work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aluminum fabrication work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>civil &amp; plumbing work @ BMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MaterialDescription\n",
       "0    AIRTEL BILLS 22aug TO 23 AUG    2012\n",
       "1   AIRTEL MOBILE BILLS 23nov O 22 dec 12\n",
       "2               aluminum fabrication work\n",
       "3               aluminum fabrication work\n",
       "4             civil & plumbing work @ BMT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = 'UNSPSC_Final'\n",
    "y = df[output]\n",
    "features = ['MaterialDescription']\n",
    "X = df[features]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading stopwords from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()  # Download text data sets, including stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "\n",
    "def description_to_words(review_text):\n",
    "    \n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aluminum fabrication work\n"
     ]
    }
   ],
   "source": [
    "clean_review = description_to_words(df['MaterialDescription'][3] )\n",
    "print(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set movie reviews...\n",
      "\n",
      "Description 1000 of 45001\n",
      "\n",
      "Description 2000 of 45001\n",
      "\n",
      "Description 3000 of 45001\n",
      "\n",
      "Description 4000 of 45001\n",
      "\n",
      "Description 5000 of 45001\n",
      "\n",
      "Description 6000 of 45001\n",
      "\n",
      "Description 7000 of 45001\n",
      "\n",
      "Description 8000 of 45001\n",
      "\n",
      "Description 9000 of 45001\n",
      "\n",
      "Description 10000 of 45001\n",
      "\n",
      "Description 11000 of 45001\n",
      "\n",
      "Description 12000 of 45001\n",
      "\n",
      "Description 13000 of 45001\n",
      "\n",
      "Description 14000 of 45001\n",
      "\n",
      "Description 15000 of 45001\n",
      "\n",
      "Description 16000 of 45001\n",
      "\n",
      "Description 17000 of 45001\n",
      "\n",
      "Description 18000 of 45001\n",
      "\n",
      "Description 19000 of 45001\n",
      "\n",
      "Description 20000 of 45001\n",
      "\n",
      "Description 21000 of 45001\n",
      "\n",
      "Description 22000 of 45001\n",
      "\n",
      "Description 23000 of 45001\n",
      "\n",
      "Description 24000 of 45001\n",
      "\n",
      "Description 25000 of 45001\n",
      "\n",
      "Description 26000 of 45001\n",
      "\n",
      "Description 27000 of 45001\n",
      "\n",
      "Description 28000 of 45001\n",
      "\n",
      "Description 29000 of 45001\n",
      "\n",
      "Description 30000 of 45001\n",
      "\n",
      "Description 31000 of 45001\n",
      "\n",
      "Description 32000 of 45001\n",
      "\n",
      "Description 33000 of 45001\n",
      "\n",
      "Description 34000 of 45001\n",
      "\n",
      "Description 35000 of 45001\n",
      "\n",
      "Description 36000 of 45001\n",
      "\n",
      "Description 37000 of 45001\n",
      "\n",
      "Description 38000 of 45001\n",
      "\n",
      "Description 39000 of 45001\n",
      "\n",
      "Description 40000 of 45001\n",
      "\n",
      "Description 41000 of 45001\n",
      "\n",
      "Description 42000 of 45001\n",
      "\n",
      "Description 43000 of 45001\n",
      "\n",
      "Description 44000 of 45001\n",
      "\n",
      "Description 45000 of 45001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "num_description = df['MaterialDescription'].size\n",
    "print(\"Cleaning and parsing the training set movie reviews...\\n\")\n",
    "clean_description = []\n",
    "for i in range(0, num_description):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(\"Description %d of %d\\n\" % ( i+1, num_description))                                                                  \n",
    "    clean_description.append( description_to_words(df['MaterialDescription'][i] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the list containing the useful words extracted from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airtel bills aug aug', 'airtel mobile bills nov dec', 'aluminum fabrication work', 'aluminum fabrication work', 'civil plumbing work bmt', 'electrical wk elr lab mhb', 'glass door fr gastro main door', 'hosp tack fixing st flr medicine', 'magazine week magic pot', 'magazine week magic pot', 'magazine week magic pot dec', 'magazine week magic pot dec', 'marketing referral fee', 'marketing referral fee', 'nuclear medicine ac repair', 'providing fixing corner guards', 'providing fixing corner guards', 'providing laying cable forcctv camera', 'service charges maint bio medical', 'service chrg fr house keeping staff', 'service chrg fr house keeping staff', 'service chrg fr house keeping staff', 'service chrg fr house keeping staff', 'service chrg fr house keeping staff', 'service chrg fr house keeping staff', 'service chrg fr house keeping staff', 'service chrg fr house keeping staff', 'service chrg fr house keeping staff', 'service chrg fr month may feb', 'service chrg fr month may feb', 'tow ch ups fire invest rad dept', 'tow ren cgs rita rf gnrte rdi frqcy', 'tow ren cgs rita rf gnrte rdi frqcy', 'tow upholstery rec chair nephr', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte', 'towards abl blood gas electrolyte']\n"
     ]
    }
   ],
   "source": [
    "print(clean_description[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating bag of words from the useful word extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the bag of words...\\n\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_description)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45001, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
